services:
  # Service for postgres database instance
  postgres-db:
    #Container name
    container_name: postgres-db

    #Build context 
    build:
      context: ./postgres
      dockerfile: dockerfile

    #Set restart to always
    restart: always

    # Share container network with pgadmin through postgre-pgadmin
    # Share container network with postgre-app through postgre-app
    networks:
      - postgre-pgadmin
      - postgre-app

    # Get environment from development.env
    env_file:
      - ./postgres/config/development.env

    # Mount volume postgresql-data to directory at the /bitnami/postgresql path
    # Mount init scripts for postgresql instance to run at start up
    volumes:
      - postgresql-data:/bitnami/postgresql
      - ./postgres/init_scripts:/docker-entrypoint-initdb.d

  # Service for pgadmin instance
  postgres-db-pgadmin:
    #Container name
    container_name: postgres-db-pgadmin

    #Build context 
    build:
      context: ./postgres-db-pgadmin
      dockerfile: dockerfile

    #Set restart to always
    restart: always

    #Depend on service postgres-db to successfully init before starting up
    depends_on:
      - postgres-db

    # Share container network with postgres-db through postgre-pgadmin
    networks:
      - postgre-pgadmin

    # Get environment from development.env
    env_file:
      - ./postgres-db-pgadmin/config/development.env

    #Forward port 8880 from localhost to port 80 in container
    ports:
      - "8880:80"

    #Mount volume pgadmin-data to directory at the /var/lib/pgadmin path
    volumes:
      - pgadmin-data:/var/lib/pgadmin
      # Mount servers json 
      - ./postgres-db-pgadmin/dump/servers.json:/pgadmin4/servers.json
      # Mount pg password to servers
      - ./postgres-db-pgadmin/dump/.pgpass.conf:/pgadmin4/pgpass
    # Grant permissions to pgpass
    entrypoint: >
      sh -c " cp -f /pgadmin4/pgpass /var/lib/pgadmin; chmod 600 /var/lib/pgadmin/pgpass; /entrypoint.sh "

  # Service for python application
  python-application:
    # Container name
    container_name: python-application

    # Build context 
    build:
      context: ./python-application
      dockerfile: dockerfile

    # Get environment from development.env
    env_file:
      - ./python-application/config/development.env

    #Set restart to always
    restart: always

    # Share container network with postgres-db through postgre-app
    networks:
      - postgre-app

    #Mount volume
    volumes:
      - ./python-application:/app:bind

  # Service for spark master node
  spark-master:
    # Container name
    container_name: spark-master
    # Build context 
    build:
      context: ./spark/spark-master
      dockerfile: dockerfile
    ports:
      - '8078:8080'
    # Get environment from development.env
    env_file:
      - ./spark/spark-master/config/development.env
    # Mount configuration files
    volumes:
      - ./spark/spark-master/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    # Share container network with spark cluster through spark-cluster
    networks:
      - spark-cluster

  # Service for spark worker node
  spark-worker:
    # Container name
    container_name: spark-worker
    # Build context 
    build:
      context: ./spark/spark-worker
      dockerfile: dockerfile
    # Get environment from development.env
    env_file:
      - ./spark/spark-worker/config/development.env
    # Share container network with spark cluster through spark-cluster
    networks:
      - spark-cluster

  # Service for spark notebook
  spark-notebook:
    # Container name
    container_name: spark-notebook
    # Build context 
    build:
      context: ./spark/spark-notebook
      dockerfile: dockerfile
    # Set user to root
    user: root
    env_file:
      - ./spark/spark-notebook/config/development.env
    # Mount configuration files
    volumes:
      - ./spark/spark-notebook/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
    ports:
      - "8888:8888"
      - "4040:4040"
    networks:
      - spark-cluster

  # Service for Kafka - Kafka broker 0
  kafka-broker-0:
    container_name: kafka-broker-0
    image: bitnami/kafka
    # Connect to kafka-cluster network
    networks:
      - kafka-cluster
    # Add volume for kafka data
    volumes:
      - kafka_0_data:/bitnami/kafka
    # Environment file
    env_file:
      - ./kafka/broker-0/config/development.env
    healthcheck:
      test: "bash -c 'printf \"\" > /dev/tcp/127.0.0.1/9092; exit $$?;'"
      interval: 5s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Services for kafka - Kafka broker 1
  kafka-broker-1:
    container_name: kafka-broker-1
    image: bitnami/kafka
    # Connect to kafka-cluster network
    networks:
      - kafka-cluster
    volumes:
      # Add volume for kafka data
      - kafka_1_data:/bitnami/kafka
    env_file:
      - ./kafka/broker-1/config/development.env
    healthcheck:
      test: "bash -c 'printf \"\" > /dev/tcp/127.0.0.1/9092; exit $$?;'"
      interval: 5s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Schema registry 
  kafka-schema-registry:
    container_name: kafka-schema-registry
    image: bitnami/schema-registry
    # Connect to kafka-cluster network
    networks:
      - kafka-cluster
    # Service depends on kafka cluster to sucessfully spin up
    depends_on:
      - kafka-broker-0
      - kafka-broker-1
    env_file:
      - ./kafka/schema-registry/config/development.env

  #Kafka ui service
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui
    env_file:
      - ./kafka/ui/config/development.env
    volumes:
      - ./kafka/ui/config.yml:/etc/kafkaui/dynamic_config.yaml
    # Service depends on kafka cluster to sucessfully spin up
    depends_on:
      - kafka-broker-0
      - kafka-broker-1
      - kafka-schema-registry
    # Connect to kafka-cluster network
    networks:
      - kafka-cluster
    # Map ports
    ports:
      - "8879:8080"
    healthcheck:
      test: wget --no-verbose --tries=1 --spider localhost:8080 || exit 1
      interval: 5s
      timeout: 10s
      retries: 3
      start_period: 30s

networks:
  postgre-pgadmin:
    driver: bridge
  postgre-app:
    driver: bridge
  spark-cluster:
    driver: bridge
  kafka-cluster:
    driver: bridge

volumes:
  pgadmin-data:
    driver: local
  postgresql-data:
    driver: local
  kafka_0_data:
    driver: local
  kafka_1_data:
    driver: local
